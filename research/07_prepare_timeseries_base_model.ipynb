{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paladin/Downloads/Bixi-OD-Matrix-Prediction/Bixi-OD-Matrix-Prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareTimeseriesBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_od_timeseries_model_path: Path\n",
    "    base_tensor_timeseries_model_path: Path\n",
    "    trained_od_autoencoder_path: Path\n",
    "    trained_tensor_autoencoder_path: Path\n",
    "    params_learning_rate: float\n",
    "    params_time_lag : int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseriesPredictor.constants import *\n",
    "from timeseriesPredictor.utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class configurationManeger:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 secret_filepath = SECRET_FILE_PATH,                 \n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath) \n",
    "        self.secret = read_yaml(secret_filepath)        \n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_prepare_timeseries_base_model_config(self) -> PrepareTimeseriesBaseModelConfig:\n",
    "        config = self.config.prepare_timeseries_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_timeseries_base_model_config = PrepareTimeseriesBaseModelConfig(\n",
    "            root_dir = config.root_dir,           \n",
    "            base_od_timeseries_model_path = config.base_od_timeseries_model_path,    \n",
    "            base_tensor_timeseries_model_path = config.base_tensor_timeseries_model_path,                   \n",
    "            trained_od_autoencoder_path = self.config.training_autoencoder.trained_od_model_path,\n",
    "            trained_tensor_autoencoder_path= self.config.training_autoencoder.trained_tensor_model_path,\n",
    "            params_learning_rate = self.params.LEARNING_RATE_TIMESERIES ,\n",
    "            params_time_lag = self.params.TIME_LAG                \n",
    "\n",
    "        )\n",
    "\n",
    "        return prepare_timeseries_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:27:39.824134: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-18 15:27:39.885794: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-18 15:27:39.886633: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-18 15:27:41.112559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from timeseriesPredictor.logger import logging\n",
    "from box import ConfigBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareTimeseriesBaseModel:\n",
    "    def __init__(self, config: PrepareTimeseriesBaseModelConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_encoder_layer_size(autoencoder_path:Path):\n",
    "        autoencoder = keras.models.load_model(autoencoder_path)\n",
    "        encoderLayer = autoencoder.get_layer(\"encoder\")              \n",
    "        return ConfigBox({'input_shape': autoencoder.input_shape[1:],\n",
    "                         'bottleneck_shape': encoderLayer.output_shape[1:]})\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path:Path, model:keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_full_model(learning_rate, input_shape, reshape):      \n",
    "        \n",
    "        # Construct the input layer with no definite frame size.\n",
    "        inputs = keras.layers.Input(shape= input_shape)\n",
    "\n",
    "        # We will construct 2 `ConvLSTM2D` layers with batch normalization,\n",
    "        # followed by `Conv3D` and `Conv2D` layer for the spatiotemporal outputs.\n",
    "        x = keras.layers.ConvLSTM2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=\"same\",\n",
    "            return_sequences=True,\n",
    "            recurrent_activation='tanh',\n",
    "            activation=\"relu\",\n",
    "            recurrent_dropout=0\n",
    "        )(inputs)\n",
    "        x = keras.layers.TimeDistributed(keras.layers.BatchNormalization())(x)\n",
    "        x = keras.layers.TimeDistributed(keras.layers.Dropout(0.25))(x)\n",
    "        \n",
    "        x = keras.layers.ConvLSTM2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=\"same\",\n",
    "            return_sequences=True,\n",
    "            activation=\"relu\",\n",
    "            recurrent_activation='tanh',\n",
    "            recurrent_dropout=0\n",
    "        )(x)\n",
    "        x = keras.layers.TimeDistributed(keras.layers.BatchNormalization())(x)\n",
    "        x = keras.layers.TimeDistributed(keras.layers.Dropout(0.25))(x)        \n",
    "        \n",
    "        x = keras.layers.Conv3D(\n",
    "            filters=16, kernel_size=(3, 3, 3), activation=\"relu\", padding=\"same\"\n",
    "        )(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"\n",
    "        )(x)\n",
    "\n",
    "        x = keras.layers.Reshape(reshape)(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=1, kernel_size=(3, 3), activation=\"linear\", padding=\"same\"\n",
    "        )(x)        \n",
    "\n",
    "        # Next, we will build the complete model and compile it.\n",
    "        model = keras.models.Model(inputs, x)\n",
    "        model.compile(\n",
    "            loss='mean_squared_error', \n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            metrics=['MSE']\n",
    "            )        \n",
    "        \n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def update_model(self):\n",
    "        \n",
    "        autoencoder_pathes = [self.config.trained_od_autoencoder_path, self.config.trained_tensor_autoencoder_path]\n",
    "        model_pathes = [self.config.base_od_timeseries_model_path, self.config.base_tensor_timeseries_model_path]\n",
    "        \n",
    "        for autoencoder_path, model_path  in zip(autoencoder_pathes, model_pathes):\n",
    "            row, col, channel =  self.get_encoder_layer_size(autoencoder_path).bottleneck_shape            \n",
    "            input_shape = [row, col, channel, self.config.params_time_lag]\n",
    "            row, col, _ =  self.get_encoder_layer_size(autoencoder_path).input_shape\n",
    "            reshape = [row, col, channel]            \n",
    "\n",
    "            self.full_model = self._prepare_full_model(        \n",
    "            learning_rate = self.config.params_learning_rate,\n",
    "            input_shape = input_shape,\n",
    "            reshape = reshape            \n",
    "            )\n",
    "\n",
    "            self.save_model(path=model_path , model=self.full_model)\n",
    "            logging.info(f\"Timeseries base model saved at {model_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from timeseriesPredictor.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 16, 3, 7)]    0         \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 16, 16, 3, 64)     163840    \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 16, 16, 3, 64)     256       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 16, 16, 3, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 16, 16, 3, 32)     110720    \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 16, 16, 3, 32)     128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 16, 16, 3, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 16, 16, 3, 16)     13840     \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 3, 16)     2320      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 1)         28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291132 (1.11 MB)\n",
      "Trainable params: 290940 (1.11 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paladin/Downloads/Bixi-OD-Matrix-Prediction/Bixi-OD-Matrix-Prediction/venv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 25, 16, 3, 7)]    0         \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 25, 16, 3, 64)     163840    \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 25, 16, 3, 64)     256       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDi  (None, 25, 16, 3, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv_lstm2d_3 (ConvLSTM2D)  (None, 25, 16, 3, 32)     110720    \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDi  (None, 25, 16, 3, 32)     128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDi  (None, 25, 16, 3, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 25, 16, 3, 16)     13840     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 16, 3, 16)     2320      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 100, 64, 3)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 100, 64, 1)        28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291132 (1.11 MB)\n",
      "Trainable params: 290940 (1.11 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = configurationManeger()\n",
    "    prepare_timeseries_base_model_config = config.get_prepare_timeseries_base_model_config()\n",
    "    prepare_timeseries_base_model = PrepareTimeseriesBaseModel(config=prepare_timeseries_base_model_config)    \n",
    "    prepare_timeseries_base_model.update_model()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
